<p align='justify'>
I am a research scientist in the
<b>Fundamental AI Research (FAIR)</b>
group at
<b>Meta AI</b>
in NYC and study foundational topics in <b>machine learning</b> and
<b>optimization</b>, recently involving reinforcement learning, control,
optimal transport, and geometry.
My research is on learning systems that understand and interact with our world
and focuses on integrating structural information and domain knowledge into
these systems to represent non-trivial reasoning operations.
A key theme of my work in this space involves the use of optimization as
a differentiable building block in larger architectures that are end-to-end learned.
I believe that science should be open and reproducible and
freely publish my research code to <a href="https://github.com/bamos" target="_blank">GitHub</a>.
</p><br>


## <i class="fa fa-chevron-right"></i> Education
<table class="table table-hover">
  <tr>
    <td>
      <span class='cvdate'>2014&nbsp;-&nbsp;2019</span>
      <strong>Ph.D. in Computer Science</strong>, <em>Carnegie Mellon University</em>
        (0.00/0.00)
      <br>
        <p style='margin-top:-1em;margin-bottom:0em' markdown='1'>
        <br> Thesis: *<a href="https://github.com/bamos/thesis" target="_blank">Differentiable Optimization-Based Modeling for Machine Learning</a>*
        <br> Advisor: <a href="http://zicokolter.com" target="_blank">J. Zico Kolter</a>
        </p>
    </td>
  </tr>
</table>


## <i class="fa fa-chevron-right"></i> Previous Positions
<table class="table table-hover">
<tr>
  <td style='padding-right:0;'>
<span class='cvdate'>2016&nbsp;-&nbsp;2019</span>
<p markdown="1" style='margin: 0'><strong>Research Assistant</strong>, <em>Carnegie Mellon University</em><span markdown="1" style="color:grey;font-size:1.3rem;margin: 0">
(with <a href="http://zicokolter.com" target="_blank">J. Zico Kolter</a> on ML and optimization)
</span></p>
  </td>
</tr>
</table>


## <i class="fa fa-chevron-right"></i> Honors & Awards
<table class="table table-hover">
<tr>
  <td>
  <div style='float: right'>2022</div>
  <div>
    ICML Outstanding Reviewer
  </div>
  </td>
  <!-- <td class='col-md-2' style='text-align:right;'>2022</td> -->
</tr>
</table>


## <i class="fa fa-chevron-right"></i> Publications

<!-- [<a href="https://github.com/bamos/cv/blob/master/publications/all.bib">BibTeX</a>] -->
Representative publications that I am a primary author on are
<span style='background-color: #ffffd0'>highlighted.</span>
<br>
[<a href="https://scholar.google.com/citations?user=d8gdZR4AAAAJ">Google Scholar</a>; 5041+ citations, h-index: 29+]

<h2>2022</h2>
<table class="table table-hover">

<tr id="tr-amos2022tutorial" style="background-color: #ffffd0">
<td align='right' style='padding-left:0;padding-right:0;'>
1.
</td>
<td>
<a href='https://arxiv.org/abs/2202.00665' target='_blank'><img src="images/publications/amos2022tutorial.png" onerror="this.style.display='none'" class="publicationImg" /></a> 
<em><a href='https://arxiv.org/abs/2202.00665' target='_blank'>Tutorial on amortized optimization for learning to optimize over continuous domains</a> </em> 
[<a href='javascript:;'
    onclick='$("#abs_amos2022tutorial").toggle()'>abs</a>] [<a href='https://github.com/facebookresearch/amortized-optimization-tutorial' target='_blank'>code</a>] <br>
<strong>Brandon&nbsp;Amos</strong><br>
arXiv 2022  <br>

<div id="abs_amos2022tutorial" style="text-align: justify; display: none" markdown="1">
Optimization is a ubiquitous modeling tool that is often deployed in
settings that repeatedly solve similar instances of
the same problem. Amortized optimization methods use
learning to predict the solutions to problems in
these settings. This leverages the shared structure
between similar problem instances. In this tutorial, we will discuss the key design choices behind
amortized optimization, roughly categorizing 1)
models into fully-amortized and semi-amortized
approaches, and 2) learning methods into
regression-based and objective-based. We then view
existing applications through these foundations to
draw connections between them, including for
manifold optimization, variational inference, sparse
coding, meta-learning, control, reinforcement
learning, convex optimization, and deep equilibrium
networks. This framing enables us easily see, for
example, that the amortized inference in variational
autoencoders is conceptually identical to value
gradients in control and reinforcement learning as
they both use fully-amortized models with a
objective-based loss.
</div>

</td>
</tr>
</table>


## <i class="fa fa-chevron-right"></i> Open Source Repositories
<table class="table table-hover">
<tr>
  <td align='right' style='padding-right:0;padding-left:0;'>1.</td>
  <td>
    <span class='cvdate'>2022</span>
    <a href="https://github.com/facebookresearch/amortized-optimization-tutorial">facebookresearch/amortized-optimization-tutorial</a> |
    <i class="fa fas fa-star"></i> 123 |
    <em>Tutorial on amortized optimization</em>
    <!--  -->
    <!--     facebookresearch/amortized-optimization-tutorial  -->
    <!--  -->
  </td>
</tr>
</table>


## <i class="fa fa-chevron-right"></i> Invited Talks
Slides for my major presentations are open-sourced with a CC-BY license at
[bamos/presentations](https://github.com/bamos/presentations).
<table class="table table-hover">
<tr>
  <td align='right' style='padding-right:0;padding-left:0;'>1.</td>
  <td style='padding-right:0;'>
    <span class='cvdate'>2022</span>
     <em>Differentiable optimization</em>,
        <a href="https://guaguakai.github.io/IJCAI22-differentiable-optimization/">IJCAI Tutorial</a>
  </td>
</tr>
</table>


## <i class="fa fa-chevron-right"></i> Interns and Students
<table class="table table-hover">
<tr>
  <td style='padding-right:0;'>
    <span class='cvdate'>2020&nbsp;-&nbsp;2022</span>
        <a href="https://www.aaronlou.com/">Aaron Lou</a> (visiting FAIR from Cornell and Stanford)
  </td>
</tr>
</table>


## <i class="fa fa-chevron-right"></i> Professional Activities
<table class="table table-hover">
<tr>
  <td style='padding-right:0;'>
  <span class='cvdate'>2023</span>
      AAAI Senior Program Committee
  </td>
</tr>
</table>


### Reviewing
<table class="table table-hover">
<tr>
  <td style='padding-right:0;'>AAAI Conference on Artificial Intelligence</td>
</tr>
</table>


## <i class="fa fa-chevron-right"></i> Teaching
<table class="table table-hover">
<tr>
  <td style='padding-right:0'><strong>Graduate AI</strong> (CMU 15-780), TA</td>
  <td class='col-md-2' style='text-align:right; padding-left:0;'>S2017</td>
</tr>
</table>


## <i class="fa fa-chevron-right"></i> Skills
<table class="table table-hover">
<tr>
  <td class='col-md-2'>Programming</td>
  <td>
C, C++, Fortran, Haskell, Java, Lua, Make, Mathematica, Python, R, Scala
  </td>
</tr>
</table>
